{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd-dD9YoBolq"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer-lens\n",
        "!pip install fancy_einsum\n",
        "!pip install datasets\n",
        "!pip install git+https://github.com/neelnanda-io/neel-plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDEaTcMpf0Gi",
        "outputId": "530554a6-58d1-40fa-f6e6-56a258928537"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer-lens\n",
            "  Downloading transformer_lens-1.11.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.23.0 (from transformer-lens)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer-lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens)\n",
            "  Downloading jaxtyping-0.2.24-py3-none-any.whl (38 kB)\n",
            "Collecting numpy>=1.24 (from transformer-lens)\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens)\n",
            "  Downloading nvidia_cublas_cu12-12.3.4.1-py3-none-manylinux1_x86_64.whl (412.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.6/412.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.3.103-py3-none-manylinux1_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.7/867.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens)\n",
            "  Downloading nvidia_cufft_cu12-11.0.12.1-py3-none-manylinux1_x86_64.whl (98.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.4.101-py3-none-manylinux1_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.5.4.101-py3-none-manylinux1_x86_64.whl (125.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.2.0.103-py3-none-manylinux1_x86_64.whl (197.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.5/197.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_nvtx_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (13.7.0)\n",
            "Collecting torch!=2.0,!=2.1.0,>=1.10 (from transformer-lens)\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.66.1)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.35.2)\n",
            "Requirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer-lens) (4.5.0)\n",
            "Collecting wandb>=0.13.5 (from transformer-lens)\n",
            "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer-lens) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.7.1->transformer-lens)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.7.1->transformer-lens)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens) (3.9.1)\n",
            "Collecting typeguard<3,>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12>=11.4.5.107->transformer-lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12>=8.9.2.26 (from transformer-lens)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12>=12.1.3.1 (from transformer-lens)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12>=11.0.2.54 (from transformer-lens)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12>=10.3.2.106 (from transformer-lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12>=11.4.5.107 (from transformer-lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.0.106 (from transformer-lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12>=2.18.1 (from transformer-lens)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12>=12.1.105 (from transformer-lens)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens) (0.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer-lens) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: typeguard, smmap, setproctitle, sentry-sdk, pyarrow-hotfix, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, gitdb, nvidia-cusolver-cu12, GitPython, wandb, torch, datasets, accelerate, transformer-lens\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 accelerate-0.25.0 beartype-0.14.1 datasets-2.15.0 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 jaxtyping-0.2.24 multiprocess-0.70.15 numpy-1.26.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pyarrow-hotfix-0.6 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 torch-2.1.1 transformer-lens-1.11.0 typeguard-2.13.3 wandb-0.16.1\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Collecting git+https://github.com/neelnanda-io/neel-plotly\n",
            "  Cloning https://github.com/neelnanda-io/neel-plotly to /tmp/pip-req-build-4ei40jfp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/neel-plotly /tmp/pip-req-build-4ei40jfp\n",
            "  Resolved https://github.com/neelnanda-io/neel-plotly to commit 6dc24b26f8dec991908479d7445dae496b3430b7\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (1.26.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (2.1.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (5.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from neel-plotly==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->neel-plotly==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->neel-plotly==0.0.0) (2023.3.post1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->neel-plotly==0.0.0) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly->neel-plotly==0.0.0) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->neel-plotly==0.0.0) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->neel-plotly==0.0.0) (12.3.101)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->neel-plotly==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->neel-plotly==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->neel-plotly==0.0.0) (1.3.0)\n",
            "Building wheels for collected packages: neel-plotly\n",
            "  Building wheel for neel-plotly (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for neel-plotly: filename=neel_plotly-0.0.0-py3-none-any.whl size=10186 sha256=cf9702a6bd15fffcdd07da4d80d964c841068759af416c70b3e9f579a7a52f61\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9iqmgtwg/wheels/60/b4/63/92bac484ab33ad4facf74435b557ca39eb9b9294f27d74e848\n",
            "Successfully built neel-plotly\n",
            "Installing collected packages: neel-plotly\n",
            "Successfully installed neel-plotly-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1oIbXQTHBolr"
      },
      "outputs": [],
      "source": [
        "import google.colab\n",
        "IN_COLAB = True\n",
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bnVdTtyGBolu"
      },
      "outputs": [],
      "source": [
        "import plotly.io as pio\n",
        "pio.renderers.default = \"colab\"\n",
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30\n",
        "\n",
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)\n",
        "\n",
        "def add_lines(figure):\n",
        "    figure.add_vline(memorization_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(circuit_formation_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(cleanup_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6AhG_kr4Bolu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML\n",
        "import wandb\n",
        "\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin\n",
        "  # API key : 4b767df1f5ebd790345e45531f8c5196675c1c07"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UkN8NeoDghv",
        "outputId": "4f410b1d-dc4b-4807-e292-d74d898d889b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UnYBertBolw"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAan3HQ6Bolw"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "afq7d_anBolw"
      },
      "outputs": [],
      "source": [
        "p = 113\n",
        "frac_train = 0.3\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1.\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "num_epochs = 25000\n",
        "checkpoint_every = 100\n",
        "\n",
        "DATA_SEED = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GJV8EMbBolw"
      },
      "source": [
        "## Define Task\n",
        "(a^m + b^n) mod 113"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m= 6\n",
        "n= 8\n",
        "wandb_name = \"m6_n8\""
      ],
      "metadata": {
        "id": "9EoYrxMxvy-z"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvEMUmkqBolw"
      },
      "source": [
        "Input format:\n",
        "|a|b|=|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "GqWf_TfRBolw"
      },
      "outputs": [],
      "source": [
        "a_vector = einops.repeat(torch.arange(p), \"i -> (i j)\", j=p)\n",
        "b_vector = einops.repeat(torch.arange(p), \"j -> (i j)\", i=p)\n",
        "equals_vector = einops.repeat(torch.tensor(113), \" -> (i j)\", i=p, j=p)\n",
        "\n",
        "dataset = torch.stack([a_vector, b_vector, equals_vector], dim=1)\n",
        "labels = (dataset[:, 0]**m + dataset[:, 1]**n) % p\n",
        "labels = labels.to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onPtyCdyBolx"
      },
      "source": [
        "Convert this to a train + test set - 30% in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t83Xh3j-Bolx",
        "outputId": "eb1be330-b49b-49cd-89d3-05dcb2a0eda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 21,  31, 113],\n",
            "        [ 30,  98, 113],\n",
            "        [ 47,  10, 113],\n",
            "        [ 86,  21, 113],\n",
            "        [ 99,  83, 113]], device='cuda:0')\n",
            "tensor([18, 50, 96, 53, 37], device='cuda:0')\n",
            "torch.Size([3830, 3])\n",
            "tensor([[ 43,  40, 113],\n",
            "        [ 31,  42, 113],\n",
            "        [ 39,  63, 113],\n",
            "        [ 35,  61, 113],\n",
            "        [112, 102, 113]], device='cuda:0')\n",
            "tensor([103,  98,  32,  72,  29], device='cuda:0')\n",
            "torch.Size([8939, 3])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(DATA_SEED)\n",
        "indices = torch.randperm(p*p)\n",
        "cutoff = int(p*p*frac_train)\n",
        "train_indices = indices[:cutoff]\n",
        "test_indices = indices[cutoff:]\n",
        "\n",
        "train_data = dataset[train_indices]\n",
        "train_labels = labels[train_indices]\n",
        "test_data = dataset[test_indices]\n",
        "test_labels = labels[test_indices]\n",
        "\n",
        "train_data = train_data.to('cuda')\n",
        "train_labels = train_labels.to('cuda')\n",
        "test_data = test_data.to('cuda')\n",
        "test_labels = test_labels.to('cuda')\n",
        "\n",
        "print(train_data[:5])\n",
        "print(train_labels[:5])\n",
        "print(train_data.shape)\n",
        "print(test_data[:5])\n",
        "print(test_labels[:5])\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knj6Ht-PBolx"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "G8xI7nVJBolx"
      },
      "outputs": [],
      "source": [
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 4,\n",
        "    d_model = 128,\n",
        "    d_head = 32,\n",
        "    d_mlp = 512,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=p+1,\n",
        "    d_vocab_out=p,\n",
        "    n_ctx=3,\n",
        "    init_weights=True,\n",
        "    device=\"cuda\",\n",
        "    n_devices=1,\n",
        "    seed = 999,\n",
        ")\n",
        "\n",
        "model = HookedTransformer(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpmPFzIwBolx"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "FnXGAjscBolx"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAZyXt3wBolx"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "id": "h9qPR2dyBolx"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPNnUcD2Bolx",
        "outputId": "36c9aeb6-27fc-4a57-ef7b-29bf9a982b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.7329, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "tensor(4.7366, device='cuda:0', dtype=torch.float64, grad_fn=<NegBackward0>)\n",
            "Uniform loss:\n",
            "4.727387818712341\n"
          ]
        }
      ],
      "source": [
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64).to('cuda:0')\n",
        "    log_probs = logits.log_softmax(dim=-1).to('cuda:0')\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model(train_data).to('cuda:0')\n",
        "train_labels = train_labels.to('cuda:0')\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)\n",
        "print(\"Uniform loss:\")\n",
        "print(np.log(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AgFEhbkBoly"
      },
      "source": [
        "## Training with full batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "a95e87a881e048e09e0921cde965d40b",
            "d98a0acbb1774b0ab5a492cbfb51e5c6",
            "8c7a272842fc47d5831717d1ada63df6",
            "f7703969a0ff4bfdaf4c90f439de5c3a",
            "4a9a1b7a8c8944c294e70b128ddd2ce4",
            "1d67c56364184f9481d80e9e6a74d57b",
            "48599eca0f3e4dd191ae21fd269bcfca",
            "fba5a086844a4c428ec3348ecdd974e7",
            "51adb9db55a5498da4e91bdfbbed0d85",
            "48373a2dd8bd4b1e90e3a27f9133cd8a",
            "e683afb05af04122ac83139e507700fd"
          ]
        },
        "id": "5aQ60ml6Boly",
        "outputId": "9d4b4f68-9c2b-4e50-aab1-530c63c03d3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231208_225618-8qd8kclu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mech-interp/che-de-moivre/runs/8qd8kclu' target=\"_blank\">m6_n8</a></strong> to <a href='https://wandb.ai/mech-interp/che-de-moivre' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mech-interp/che-de-moivre' target=\"_blank\">https://wandb.ai/mech-interp/che-de-moivre</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mech-interp/che-de-moivre/runs/8qd8kclu' target=\"_blank\">https://wandb.ai/mech-interp/che-de-moivre/runs/8qd8kclu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a95e87a881e048e09e0921cde965d40b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99 Train Loss 2.4730773401125714 Test Loss 3.276276104860279\n",
            "Epoch 199 Train Loss 0.1953167092429177 Test Loss 1.1938837949931393\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs = []\n",
        "if TRAIN_MODEL:\n",
        "\n",
        "    wandb.init(project=\"che-de-moivre\", name=wandb_name)\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        train_logits = model(train_data)\n",
        "        train_loss = loss_fn(train_logits, train_labels)\n",
        "        train_loss.backward()\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            test_logits = model(test_data)\n",
        "            test_loss = loss_fn(test_logits, test_labels)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "        if ((epoch+1)%checkpoint_every)==0:\n",
        "            checkpoint_epochs.append(epoch)\n",
        "            model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "            print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")\n",
        "\n",
        "            wandb.log({\n",
        "            \"train_loss\": train_loss.item(),\n",
        "            \"test_loss\": test_loss.item(),\n",
        "            \"train_logit\": train_logits,\n",
        "            \"test_logit\": test_logits,\n",
        "            })\n",
        "\n",
        "            # weights\n",
        "            for name, param in model.named_parameters():\n",
        "                    wandb.log({f\"weights_{name}\": wandb.Histogram(param.data.cpu().numpy())})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aSaCfwGBolz"
      },
      "source": [
        "## Check if model groks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXckGGhiBolz"
      },
      "outputs": [],
      "source": [
        "from neel_plotly.plot import line\n",
        "line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=False, title=\"Training Curve for Modular Addition\", line_labels=['train loss', 'test loss'], toggle_x=True, toggle_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkg2Zcf9Bolz"
      },
      "source": [
        "# Analysing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF5_IqEKBol4"
      },
      "source": [
        "Get key weight matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_Qb040kBol4"
      },
      "outputs": [],
      "source": [
        "W_E = model.embed.W_E[:-1]\n",
        "print(\"W_E\", W_E.shape)\n",
        "W_neur = W_E @ model.blocks[0].attn.W_V @ model.blocks[0].attn.W_O @ model.blocks[0].mlp.W_in\n",
        "print(\"W_neur\", W_neur.shape)\n",
        "W_logit = model.blocks[0].mlp.W_out.to('cuda:0') @ model.unembed.W_U.to('cuda:0')\n",
        "print(\"W_logit\", W_logit.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSkicfVrBol4"
      },
      "source": [
        "### Looking at Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8aSSFr8Bol4"
      },
      "source": [
        "Helper variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvLDAyb5Bol5"
      },
      "outputs": [],
      "source": [
        "original_logits, cache = model.run_with_cache(dataset)\n",
        "pattern_a = cache[\"pattern\", 0, \"attn\"][:, :, -1, 0]\n",
        "pattern_b = cache[\"pattern\", 0, \"attn\"][:, :, -1, 1]\n",
        "neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "neuron_pre_acts = cache[\"pre\", 0, \"mlp\"][:, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP7_8xR8Bol5"
      },
      "source": [
        "Model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaINncisBol5"
      },
      "outputs": [],
      "source": [
        "for param_name, param in cache.items():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXgFoqwYBol5"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0].mean(dim=0)[:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RtlmBisBol5"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0][5][:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVJhXpRkBol6"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(cache[\"pattern\", 0][:, :, -1, 0], \"(a b) head -> head a b\", a=p, b=p),\n",
        "    title=\"Attention for Head 0 from a -> =\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtwC4iinBol6"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron activations\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xttFmPYVBol7"
      },
      "source": [
        "### Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5zVoPxvBol7"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(S, title=\"Singular Values\")\n",
        "imshow(U, title=\"Principal Components on the Input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRo-HyRWBol7"
      },
      "outputs": [],
      "source": [
        "# Control - random Gaussian matrix\n",
        "U, S, Vh = torch.svd(torch.randn_like(W_E))\n",
        "line(S, title=\"Singular Values Random\")\n",
        "imshow(U, title=\"Principal Components Random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2qoU0K5Bol7"
      },
      "source": [
        "## Explaining Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XYJvJArBol7"
      },
      "source": [
        "### Analyse the Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH6bC4NxBol7"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(U[:, :8].T, title=\"Principal Components of the embedding\", xaxis=\"Input Vocabulary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlUHO49tBol7"
      },
      "outputs": [],
      "source": [
        "fourier_basis = []\n",
        "fourier_basis_names = []\n",
        "fourier_basis.append(torch.ones(p))\n",
        "fourier_basis_names.append(\"Constant\")\n",
        "for freq in range(1, p//2+1):\n",
        "    fourier_basis.append(torch.sin(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Sin {freq}\")\n",
        "    fourier_basis.append(torch.cos(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Cos {freq}\")\n",
        "fourier_basis = torch.stack(fourier_basis, dim=0).cuda()\n",
        "fourier_basis = fourier_basis/fourier_basis.norm(dim=-1, keepdim=True)\n",
        "\n",
        "line(fourier_basis[:8], xaxis=\"Input\", line_labels=fourier_basis_names[:8], title=\"First 8 Fourier Components\")\n",
        "line(fourier_basis[25:29], xaxis=\"Input\", line_labels=fourier_basis_names[25:29], title=\"Middle Fourier Components\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7rcOORgBol8"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ fourier_basis.T, title=\"Verify All Fourier Vectors are Orthogonal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBpXGFZBol8"
      },
      "source": [
        "### Analyse the Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjUgCvjjBol8"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ W_E, yaxis=\"Fourier Component\", xaxis=\"Residual Stream\", y=fourier_basis_names, title=\"Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp9tV69rBol8"
      },
      "outputs": [],
      "source": [
        "line((fourier_basis @ W_E).norm(dim=-1), xaxis=\"Fourier Component\", x=fourier_basis_names, title=\"Norms of Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Key Frequencies: Models might not utilize the same frequencies even with exact settings. Adjust this according to the plot above for a meaningful ablation (progress measure evaluation).  "
      ],
      "metadata": {
        "id": "LOwRmxTc-ai3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeCah1mkBol8"
      },
      "outputs": [],
      "source": [
        "key_freqs = list(range(1, 57))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVh-1-9ZBol9"
      },
      "source": [
        "## Analyse Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV_oobpPBol9"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPpgAkLbBol-"
      },
      "source": [
        "### Neuron Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwAIITLfBol-"
      },
      "outputs": [],
      "source": [
        "fourier_neuron_acts = fourier_basis @ einops.rearrange(neuron_acts, \"(a b) neuron -> neuron a b\", a=p, b=p) @ fourier_basis.T\n",
        "# Center these by removing the mean\n",
        "fourier_neuron_acts[:, 0, 0] = 0.\n",
        "print(\"fourier_neuron_acts\", fourier_neuron_acts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI2WAa6PBol-"
      },
      "outputs": [],
      "source": [
        "neuron_freq_norm = torch.zeros(p//2, model.cfg.d_mlp).cuda()\n",
        "for freq in range(0, p//2):\n",
        "    for x in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "        for y in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "            neuron_freq_norm[freq] += fourier_neuron_acts[:, x, y]**2\n",
        "neuron_freq_norm = neuron_freq_norm / fourier_neuron_acts.pow(2).sum(dim=[-1, -2])[None, :]\n",
        "imshow(neuron_freq_norm, xaxis=\"Neuron\", yaxis=\"Freq\", y=torch.arange(1, p//2+1), title=\"Neuron Frac Explained by Freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8Xdz96kBol-",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "line(neuron_freq_norm.max(dim=0).values.sort().values, xaxis=\"Neuron\", title=\"Max Neuron Frac Explained over Freqs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gXo-IMgBol_"
      },
      "source": [
        "# Progress Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRREeHO0Bol_"
      },
      "source": [
        "## Setup Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knzxZCifBomA"
      },
      "source": [
        "Code to run a metric over every checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "catHIkOsBomA"
      },
      "outputs": [],
      "source": [
        "metric_cache = {}\n",
        "\n",
        "def get_metrics(model, metric_cache, metric_fn, name, reset=False):\n",
        "    if reset or (name not in metric_cache) or (len(metric_cache[name]) == 0):\n",
        "        metric_cache[name] = []\n",
        "\n",
        "        for c, sd in enumerate(tqdm.tqdm((model_checkpoints))):\n",
        "            model.reset_hooks()\n",
        "            model.load_state_dict(sd)\n",
        "            out = metric_fn(model)\n",
        "\n",
        "            if type(out) == torch.Tensor:\n",
        "                out = utils.to_numpy(out)\n",
        "            metric_cache[name].append(out)\n",
        "        model.load_state_dict(model_checkpoints[-1])\n",
        "        try:\n",
        "            metric_cache[name] = torch.tensor(metric_cache[name])\n",
        "        except:\n",
        "            metric_cache[name] = torch.tensor(np.array(metric_cache[name]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS7W2EccBomA"
      },
      "source": [
        "### Loss Curves"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust vertical lines accordingly"
      ],
      "metadata": {
        "id": "IudeNYYOt25J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fteEG4ewBomB"
      },
      "outputs": [],
      "source": [
        "memorization_end_epoch = 1500\n",
        "circuit_formation_end_epoch = 13300\n",
        "cleanup_end_epoch = 16600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcDnycr0BomB"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=False, title=\"Training Curve for Modular Addition\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx_uT6IwBomB"
      },
      "source": [
        "### Logit Periodicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKbW-X1KBomB"
      },
      "outputs": [],
      "source": [
        "all_logits = original_logits[:, -1, :]\n",
        "print(all_logits.shape)\n",
        "all_logits = einops.rearrange(all_logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "print(all_logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting predicted logits by each key frequencies"
      ],
      "metadata": {
        "id": "7SS6zG5PYJGF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kifKlaOBomB"
      },
      "outputs": [],
      "source": [
        "coses = {}\n",
        "for freq in key_freqs:\n",
        "    #print(\"Freq:\", freq)\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).cuda()\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    coses[freq] = cube_predicted_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine Similarity: A metric evaluating how well predicted logits are explained by each key frequencies"
      ],
      "metadata": {
        "id": "mdZIWa6ZYfC3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk8Rh5DsBomB"
      },
      "outputs": [],
      "source": [
        "approximated_logits = torch.zeros_like(all_logits)\n",
        "for freq in key_freqs:\n",
        "    print(\"Freq:\", freq)\n",
        "    coeff = (all_logits.to('cuda:0') * coses[freq].to('cuda:0')).sum()\n",
        "    print(\"Coeff:\", coeff)\n",
        "    cosine_sim = coeff.to('cuda:0') / all_logits.to('cuda:0').norm()\n",
        "    print(\"Cosine Sim:\", cosine_sim)\n",
        "    approximated_logits = approximated_logits.to('cuda:0')\n",
        "    approximated_logits += coeff.to('cuda:0') * coses[freq]\n",
        "residual = all_logits.to('cuda:0') - approximated_logits.to('cuda:0')\n",
        "print(\"Residual size:\", residual.norm())\n",
        "print(\"Residual fraction of norm:\", residual.to('cuda:0').norm()/all_logits.to('cuda:0').norm())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cosine Similarity on a random vector"
      ],
      "metadata": {
        "id": "F0iKHTc5abgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_logit_cube = torch.randn_like(all_logits)\n",
        "print((all_logits * random_logit_cube).sum() / random_logit_cube.norm()/all_logits.norm())"
      ],
      "metadata": {
        "id": "4aypJAX4Zzh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuYKLHExBomC"
      },
      "source": [
        "#### Look During Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_cube = []\n",
        "for freq in range(1, p//2 + 1):\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).cuda()\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    cos_cube.append(cube_predicted_logits)\n",
        "cos_cube = torch.stack(cos_cube, dim=0)\n",
        "print(cos_cube.shape)"
      ],
      "metadata": {
        "id": "G5QuFtEhbzKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cos_coeffs(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals\n",
        "\n",
        "\n",
        "get_metrics(model, metric_cache, get_cos_coeffs, \"cos_coeffs\")\n",
        "print(metric_cache[\"cos_coeffs\"].shape)"
      ],
      "metadata": {
        "id": "MyvykGYQb1z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = line(metric_cache[\"cos_coeffs\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Coefficients with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Coefficient\", return_fig=True)\n",
        "add_lines(fig)"
      ],
      "metadata": {
        "id": "FEufZN8Eb7Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals / logits.norm()"
      ],
      "metadata": {
        "id": "N7Z0BUuQgYX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this  cell again if graph not shown"
      ],
      "metadata": {
        "id": "dNImOeEZwM1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(model, metric_cache, get_cos_sim, \"cos_sim\")\n",
        "fig = line(metric_cache[\"cos_sim\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Cosine Sim with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ],
      "metadata": {
        "id": "TXZlxd0chIJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_residual_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    residual = logits - (vals[:, None, None, None] * cos_cube).sum(dim=0)\n",
        "    return residual.norm() / logits.norm()"
      ],
      "metadata": {
        "id": "KBxPBJDug4_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell again if graph not shown"
      ],
      "metadata": {
        "id": "XBCg7zGCwUj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(model, metric_cache, get_residual_cos_sim, \"residual_cos_sim\")\n",
        "fig = line([metric_cache[\"cos_sim\"][:, i] for i in range(p//2)]+[metric_cache[\"residual_cos_sim\"]], line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)]+[\"residual\"], title=\"Cosine Sim with Predicted Logits + Residual\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ],
      "metadata": {
        "id": "NffJgj0fhDVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94tTNdcZBomD"
      },
      "source": [
        "## Fourier Norms of neuron activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLFKR0DHBomD"
      },
      "outputs": [],
      "source": [
        "neuron_acts_square = einops.rearrange(neuron_acts, \"(a b) neur -> a b neur\", a=p, b=p).clone()\n",
        "# Center it\n",
        "neuron_acts_square -= einops.reduce(neuron_acts_square, \"a b neur -> 1 1 neur\", \"mean\")\n",
        "neuron_acts_square_fourier = einsum(\"a b neur, fa a, fb b -> fa fb neur\", neuron_acts_square, fourier_basis, fourier_basis)\n",
        "imshow(neuron_acts_square_fourier.norm(dim=-1), xaxis=\"Fourier Component b\", yaxis=\"Fourier Component a\", title=\"Norms of neuron activations by Fourier Component\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(\n",
        "    neuron_acts_square_fourier.norm(dim=-1)[1:, 1:],\n",
        "    xaxis=\"Fourier Component b\",\n",
        "    yaxis=\"Fourier Component a\",\n",
        "    title=\"Norms of neuron activations by Fourier Component Excluding Constant\",\n",
        "    x=fourier_basis_names[1:],\n",
        "    y=fourier_basis_names[1:]\n",
        ")"
      ],
      "metadata": {
        "id": "7bOBAVDgxYfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INUz70m9BomI"
      },
      "source": [
        "## Excluded Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mBJ4SIXBomI"
      },
      "outputs": [],
      "source": [
        "approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "# approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "a = torch.arange(p)[:, None]\n",
        "b = torch.arange(p)[None, :]\n",
        "for freq in key_freqs:\n",
        "    cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).cuda()\n",
        "    cos_apb_vec /= cos_apb_vec.norm()\n",
        "    cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "    sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).cuda()\n",
        "    sin_apb_vec /= sin_apb_vec.norm()\n",
        "    sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "excluded_logits = excluded_neuron_acts @ W_logit\n",
        "print(loss_fn(excluded_logits[train_indices], train_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We found empirically that for m=n where n is a fixed positive even integer, the models always learn to only utilize cosine frequencies, even with different hyperparameters. Uncomment the sine part if you're interested in ablating sine frequencies too"
      ],
      "metadata": {
        "id": "n7blFGnY6wQ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZPiq9YlBomI"
      },
      "outputs": [],
      "source": [
        "def get_excluded_loss(model):\n",
        "    logits, cache = model.run_with_cache(dataset)\n",
        "    logits = logits[:, -1, :]\n",
        "    neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "    approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "    # approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "    a = torch.arange(p)[:, None]\n",
        "    b = torch.arange(p)[None, :]\n",
        "    for freq in key_freqs:\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).cuda()\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).cuda()\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "        \"\"\"\n",
        "        sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).cuda()\n",
        "        sin_apb_vec /= sin_apb_vec.norm()\n",
        "        sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "        \"\"\"\n",
        "    excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "    residual_stream_final = excluded_neuron_acts @ model.blocks[0].mlp.W_out + cache[\"resid_mid\", 0][:, -1, :]\n",
        "    excluded_logits = residual_stream_final @ model.unembed.W_U\n",
        "    excluded_loss = loss_fn(excluded_logits[train_indices], train_labels)\n",
        "\n",
        "    wandb.log({\n",
        "            \"excluded_logits\":excluded_logits,\n",
        "            \"excluded_loss\": excluded_loss\n",
        "            })\n",
        "    return excluded_loss\n",
        "get_excluded_loss(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcwtD0pXBomJ"
      },
      "outputs": [],
      "source": [
        "get_metrics(model, metric_cache, get_excluded_loss, \"excluded_loss\", reset=True)\n",
        "print(metric_cache[\"excluded_loss\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "-rO67bMVG6l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excluded Loss : Train Loss with ablation"
      ],
      "metadata": {
        "id": "1_gRplmt70N_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKFZoZCKBomJ"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100], metric_cache[\"excluded_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Excluded Loss Curve\", line_labels=['train', 'test', \"excluded_loss\"], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "\n",
        "add_lines(fig)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cuda_good",
      "language": "python",
      "name": "jupyter310cuda"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a95e87a881e048e09e0921cde965d40b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d98a0acbb1774b0ab5a492cbfb51e5c6",
              "IPY_MODEL_8c7a272842fc47d5831717d1ada63df6",
              "IPY_MODEL_f7703969a0ff4bfdaf4c90f439de5c3a"
            ],
            "layout": "IPY_MODEL_4a9a1b7a8c8944c294e70b128ddd2ce4"
          }
        },
        "d98a0acbb1774b0ab5a492cbfb51e5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d67c56364184f9481d80e9e6a74d57b",
            "placeholder": "​",
            "style": "IPY_MODEL_48599eca0f3e4dd191ae21fd269bcfca",
            "value": "  1%"
          }
        },
        "8c7a272842fc47d5831717d1ada63df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba5a086844a4c428ec3348ecdd974e7",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51adb9db55a5498da4e91bdfbbed0d85",
            "value": 248
          }
        },
        "f7703969a0ff4bfdaf4c90f439de5c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48373a2dd8bd4b1e90e3a27f9133cd8a",
            "placeholder": "​",
            "style": "IPY_MODEL_e683afb05af04122ac83139e507700fd",
            "value": " 248/25000 [00:06&lt;09:53, 41.68it/s]"
          }
        },
        "4a9a1b7a8c8944c294e70b128ddd2ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d67c56364184f9481d80e9e6a74d57b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48599eca0f3e4dd191ae21fd269bcfca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fba5a086844a4c428ec3348ecdd974e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51adb9db55a5498da4e91bdfbbed0d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48373a2dd8bd4b1e90e3a27f9133cd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e683afb05af04122ac83139e507700fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}